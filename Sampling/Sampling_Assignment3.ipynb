{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ad3695b",
   "metadata": {},
   "source": [
    "# Sampling assignment 3\n",
    "##### Name - Ikshit\n",
    "##### Roll no. - 102003403\n",
    "###### Group - 3CO16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc9d04ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc5ff94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\IKSHIT\\\\Downloads\\\\Sampling_Assignment-main\\\\Sampling_Assignment-main\\\\Creditcard_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "066ecf75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>575</td>\n",
       "      <td>-0.572263</td>\n",
       "      <td>0.731748</td>\n",
       "      <td>1.541254</td>\n",
       "      <td>0.150506</td>\n",
       "      <td>1.108974</td>\n",
       "      <td>0.372152</td>\n",
       "      <td>1.084879</td>\n",
       "      <td>-0.146329</td>\n",
       "      <td>-0.274447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143508</td>\n",
       "      <td>-0.107582</td>\n",
       "      <td>-0.418263</td>\n",
       "      <td>-0.731029</td>\n",
       "      <td>0.877525</td>\n",
       "      <td>-0.364150</td>\n",
       "      <td>-0.177509</td>\n",
       "      <td>-0.256545</td>\n",
       "      <td>26.72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>579</td>\n",
       "      <td>-1.296845</td>\n",
       "      <td>-0.511605</td>\n",
       "      <td>2.404726</td>\n",
       "      <td>-0.310762</td>\n",
       "      <td>-0.319551</td>\n",
       "      <td>-0.542842</td>\n",
       "      <td>-0.173310</td>\n",
       "      <td>0.260423</td>\n",
       "      <td>-1.202688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071270</td>\n",
       "      <td>-0.161175</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.285390</td>\n",
       "      <td>0.281069</td>\n",
       "      <td>-0.370130</td>\n",
       "      <td>0.043410</td>\n",
       "      <td>0.092318</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>579</td>\n",
       "      <td>1.214170</td>\n",
       "      <td>0.210481</td>\n",
       "      <td>0.484651</td>\n",
       "      <td>0.479768</td>\n",
       "      <td>-0.261955</td>\n",
       "      <td>-0.527039</td>\n",
       "      <td>0.021782</td>\n",
       "      <td>-0.106888</td>\n",
       "      <td>-0.037631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224292</td>\n",
       "      <td>-0.594609</td>\n",
       "      <td>0.159877</td>\n",
       "      <td>0.091873</td>\n",
       "      <td>0.140964</td>\n",
       "      <td>0.227406</td>\n",
       "      <td>-0.017389</td>\n",
       "      <td>0.016030</td>\n",
       "      <td>5.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>580</td>\n",
       "      <td>1.267030</td>\n",
       "      <td>-0.071114</td>\n",
       "      <td>0.037680</td>\n",
       "      <td>0.512683</td>\n",
       "      <td>0.242392</td>\n",
       "      <td>0.705212</td>\n",
       "      <td>-0.226582</td>\n",
       "      <td>0.109483</td>\n",
       "      <td>0.657565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164468</td>\n",
       "      <td>-0.177225</td>\n",
       "      <td>-0.222918</td>\n",
       "      <td>-1.245505</td>\n",
       "      <td>0.678360</td>\n",
       "      <td>0.525059</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>12.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>581</td>\n",
       "      <td>1.153758</td>\n",
       "      <td>0.132273</td>\n",
       "      <td>0.382969</td>\n",
       "      <td>1.405063</td>\n",
       "      <td>-0.224287</td>\n",
       "      <td>-0.197295</td>\n",
       "      <td>0.020653</td>\n",
       "      <td>0.029260</td>\n",
       "      <td>0.412254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107809</td>\n",
       "      <td>-0.125231</td>\n",
       "      <td>-0.057041</td>\n",
       "      <td>0.073082</td>\n",
       "      <td>0.633977</td>\n",
       "      <td>-0.310685</td>\n",
       "      <td>0.033590</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>13.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>772 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0       0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1       0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "767   575 -0.572263  0.731748  1.541254  0.150506  1.108974  0.372152   \n",
       "768   579 -1.296845 -0.511605  2.404726 -0.310762 -0.319551 -0.542842   \n",
       "769   579  1.214170  0.210481  0.484651  0.479768 -0.261955 -0.527039   \n",
       "770   580  1.267030 -0.071114  0.037680  0.512683  0.242392  0.705212   \n",
       "771   581  1.153758  0.132273  0.382969  1.405063 -0.224287 -0.197295   \n",
       "\n",
       "           V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0    0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
       "1   -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
       "2    0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412   \n",
       "3    0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
       "4    0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "767  1.084879 -0.146329 -0.274447  ... -0.143508 -0.107582 -0.418263   \n",
       "768 -0.173310  0.260423 -1.202688  ... -0.071270 -0.161175  0.088496   \n",
       "769  0.021782 -0.106888 -0.037631  ... -0.224292 -0.594609  0.159877   \n",
       "770 -0.226582  0.109483  0.657565  ... -0.164468 -0.177225 -0.222918   \n",
       "771  0.020653  0.029260  0.412254  ... -0.107809 -0.125231 -0.057041   \n",
       "\n",
       "          V24       V25       V26       V27       V28  Amount  Class  \n",
       "0    0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1   -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      1  \n",
       "2   -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3   -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4    0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "..        ...       ...       ...       ...       ...     ...    ...  \n",
       "767 -0.731029  0.877525 -0.364150 -0.177509 -0.256545   26.72      0  \n",
       "768  0.285390  0.281069 -0.370130  0.043410  0.092318   80.00      0  \n",
       "769  0.091873  0.140964  0.227406 -0.017389  0.016030    5.98      0  \n",
       "770 -1.245505  0.678360  0.525059  0.002920 -0.003333   12.36      0  \n",
       "771  0.073082  0.633977 -0.310685  0.033590  0.015250   13.79      0  \n",
       "\n",
       "[772 rows x 31 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6fd1140",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"Class\"]\n",
    "X = data[data.columns.drop(\"Class\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f34d4a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\ikshit\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ikshit\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\ikshit\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ikshit\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.21.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ikshit\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\ikshit\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ecd2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0eea27c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72dd5ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit predictor and target variable\n",
    "x_smote, y_smote = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3c1f070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    763\n",
       "1    763\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c089b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    763\n",
       "1      9\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f18a4",
   "metadata": {},
   "source": [
    "## creating random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f245ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform random sampling\n",
    "sample_size = 100\n",
    "x_s1 = x_smote.sample(n=sample_size, random_state=42)\n",
    "y_s1 = y_smote.sample(n=sample_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47b3ec52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Time        V1        V2        V3        V4        V5        V6  \\\n",
      "1439   411 -2.192553  1.898783 -1.545596  3.887038 -0.516677 -1.414509   \n",
      "76      49 -0.549626  0.418949  1.729833  0.203065 -0.187012  0.253878   \n",
      "1010   483 -0.955497  0.352127  1.732675  0.209959  0.971484 -0.903126   \n",
      "660    499  1.255439  0.307729  0.292700  0.699873 -0.428876 -1.088456   \n",
      "1132   509 -0.113581  0.974440 -0.429355  1.961038 -0.420940 -1.205406   \n",
      "...    ...       ...       ...       ...       ...       ...       ...   \n",
      "988    485 -2.468444 -2.686394  0.983967  2.074983  1.130155 -1.065178   \n",
      "570    427 -0.847312  0.854261  0.338816  0.890137  0.804751  1.165501   \n",
      "1124   316 -1.434679  1.436673 -0.851474  2.569632 -0.027403 -0.809312   \n",
      "1163   201 -0.138074  0.240264  0.657463  0.219531  0.990144  0.286447   \n",
      "654    495 -0.239505 -3.940241 -0.147576 -0.671347 -2.239256  0.908178   \n",
      "\n",
      "            V7        V8        V9  ...       V20       V21       V22  \\\n",
      "1439 -2.449167  1.337956 -2.676744  ...  0.120183  0.490277 -0.061385   \n",
      "76    0.500894  0.251256 -0.227985  ...  0.016970  0.115062  0.418529   \n",
      "1010  0.871845 -0.155439 -0.143787  ... -0.089512  0.074067  0.283374   \n",
      "660   0.043840 -0.167739  0.128854  ... -0.121156 -0.294795 -0.882126   \n",
      "1132 -0.916610  0.405049 -1.055154  ...  0.003311  0.022013 -0.518887   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "988   0.294648 -0.086847 -0.232793  ...  1.811382  0.534870  0.267527   \n",
      "570  -0.081408  0.879014 -0.394737  ...  0.081904 -0.046690 -0.075301   \n",
      "1124 -1.495057  0.931071 -1.796421  ...  0.064074  0.279616 -0.162644   \n",
      "1163  0.050837  0.205685 -0.012692  ...  0.023897 -0.072530 -0.221033   \n",
      "654  -0.377398  0.157943 -1.595928  ...  1.217690  0.076296 -1.132178   \n",
      "\n",
      "           V23       V24       V25       V26       V27       V28      Amount  \n",
      "1439 -0.445336  0.320967  0.050439  0.175042  0.251647 -0.137436    0.043244  \n",
      "76   -0.065133  0.264981  0.003958  0.395969  0.027182  0.043506   59.990000  \n",
      "1010 -0.236796  0.376584  0.389675 -0.449856 -0.106370 -0.123673    7.841109  \n",
      "660   0.136846  0.327949  0.194459  0.096516 -0.027271  0.029491    1.980000  \n",
      "1132 -0.100074  0.334320  0.153284  0.126446  0.086646 -0.035978    0.794481  \n",
      "...        ...       ...       ...       ...       ...       ...         ...  \n",
      "988   1.209062 -0.208643  0.271953 -0.113306 -0.221943  0.035120  458.442896  \n",
      "570  -0.308479 -1.733137  0.087036 -0.129209  0.294334  0.071198   11.360000  \n",
      "1124 -0.238544 -0.299293 -0.482806  0.140164  0.250332 -0.005910    0.364155  \n",
      "1163  0.165989 -1.312263 -1.269755  0.155550  0.195397  0.189242    1.042024  \n",
      "654  -0.486820 -0.302911 -0.304121 -0.469811 -0.077517  0.151745  834.840000  \n",
      "\n",
      "[100 rows x 30 columns] 1439    1\n",
      "76      0\n",
      "1010    1\n",
      "660     0\n",
      "1132    1\n",
      "       ..\n",
      "988     1\n",
      "570     0\n",
      "1124    1\n",
      "1163    1\n",
      "654     0\n",
      "Name: Class, Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(x_s1,y_s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d179a984",
   "metadata": {},
   "source": [
    "## systematic sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2d835765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Time        V1        V2        V3        V4        V5        V6  \\\n",
      "5        2 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728   \n",
      "20      16  0.694885 -1.361819  1.029221  0.834159 -1.191209  1.309109   \n",
      "35      26 -0.535388  0.865268  1.351076  0.147575  0.433680  0.086983   \n",
      "50      35  1.199356  0.129953  0.863585  1.002635 -0.783761 -0.884679   \n",
      "65      44 -0.899992  0.136255  1.883665 -0.208996  1.051441  1.905241   \n",
      "...    ...       ...       ...       ...       ...       ...       ...   \n",
      "1460    98  0.762355  0.292903  0.485505  0.394367  0.243649 -0.248218   \n",
      "1475   519 -2.023441 -2.169072  2.167927  1.349799  2.242992  0.445949   \n",
      "1490    68  0.893303  0.284746  0.388240  0.410766  0.187662 -0.197651   \n",
      "1505   473 -2.699661 -2.579339  1.194558  1.946305  1.295853 -1.038193   \n",
      "1520   546 -1.129296  0.116183  1.008085 -0.382686  0.660663 -0.449522   \n",
      "\n",
      "            V7        V8        V9  ...       V20       V21       V22  \\\n",
      "5     0.476201  0.260314 -0.568671  ...  0.084968 -0.208254 -0.559825   \n",
      "20   -0.878586  0.445290 -0.446196  ... -0.138334 -0.295583 -0.571955   \n",
      "35    0.693039  0.179742 -0.285642  ... -0.283264  0.049526  0.206537   \n",
      "50   -0.040743 -0.208069  0.392478  ... -0.072620 -0.042468  0.198474   \n",
      "65    0.241423  0.647631 -0.053466  ... -0.121726 -0.081500 -0.016926   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1460  0.115252  0.036135 -0.232469  ... -0.079051 -0.166590 -0.452269   \n",
      "1475 -2.141536  0.832626  0.685135  ...  0.584643  0.429408  1.105088   \n",
      "1490  0.056088  0.051064 -0.239468  ... -0.076012 -0.184635 -0.509101   \n",
      "1505  0.415540 -0.082228 -0.250010  ...  1.741363  0.564919  0.410427   \n",
      "1520  0.233536  0.069271  0.021632  ... -0.012633 -0.201367 -0.319864   \n",
      "\n",
      "           V23       V24       V25       V26       V27       V28      Amount  \n",
      "5    -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080    3.670000  \n",
      "20   -0.050881 -0.304215  0.072001 -0.422234  0.086553  0.063499  231.710000  \n",
      "35   -0.187108  0.000753  0.098117 -0.553471 -0.078306  0.025427    1.770000  \n",
      "50   -0.033010  1.013290  0.559098  0.401818 -0.005865  0.017936    0.990000  \n",
      "65   -0.147706 -1.384620 -0.024352  0.412659 -0.106776 -0.190476   21.550000  \n",
      "...        ...       ...       ...       ...       ...       ...         ...  \n",
      "1460  0.028503 -0.192914  0.212542  0.008437 -0.028324 -0.013739    2.347605  \n",
      "1475  0.241834 -0.770699 -0.199958  0.810878 -0.096309 -0.169021    1.389911  \n",
      "1490  0.050694 -0.237712  0.198709  0.044248 -0.022428 -0.005061    2.451996  \n",
      "1505  1.110360 -0.183397  0.297894 -0.195509 -0.228662  0.009507  443.170430  \n",
      "1520 -0.182667 -0.119413 -0.221947  0.210648 -0.279461 -0.299275    1.058970  \n",
      "\n",
      "[102 rows x 30 columns] 5       0\n",
      "20      0\n",
      "35      0\n",
      "50      0\n",
      "65      0\n",
      "       ..\n",
      "1460    1\n",
      "1475    1\n",
      "1490    1\n",
      "1505    1\n",
      "1520    1\n",
      "Name: Class, Length: 102, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Set the size of the interval\n",
    "interval = mt.floor(x_smote.shape[0] / 100)\n",
    "\n",
    "# Set the starting index\n",
    "start = 5\n",
    "\n",
    "# Get the subset of data points using the interval and starting index\n",
    "x_s2 = x_smote.iloc[start::interval]\n",
    "y_s2 = y_smote.iloc[start::interval]\n",
    "\n",
    "# Print the subset of data points\n",
    "print(x_s2, y_s2)\n",
    "#This code sets the size of the interval as the floor division of the number of data points by 100\n",
    "#sets the starting index to 5, and gets the subset of data points using the interval and starting index.\n",
    "#Finally, it prints the subset of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "57d5d9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 30)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_s2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ddb86fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>283.005181</td>\n",
       "      <td>-0.176963</td>\n",
       "      <td>0.217169</td>\n",
       "      <td>0.875172</td>\n",
       "      <td>0.285628</td>\n",
       "      <td>-0.005029</td>\n",
       "      <td>0.159081</td>\n",
       "      <td>0.123329</td>\n",
       "      <td>-0.057547</td>\n",
       "      <td>-0.030384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>-0.096995</td>\n",
       "      <td>-0.040344</td>\n",
       "      <td>-0.002501</td>\n",
       "      <td>0.114337</td>\n",
       "      <td>0.022782</td>\n",
       "      <td>0.023353</td>\n",
       "      <td>-0.017045</td>\n",
       "      <td>68.668290</td>\n",
       "      <td>0.011658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>171.834196</td>\n",
       "      <td>1.294724</td>\n",
       "      <td>1.173401</td>\n",
       "      <td>1.031878</td>\n",
       "      <td>1.258758</td>\n",
       "      <td>1.098143</td>\n",
       "      <td>1.225682</td>\n",
       "      <td>0.852075</td>\n",
       "      <td>0.830144</td>\n",
       "      <td>0.878183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609335</td>\n",
       "      <td>0.607228</td>\n",
       "      <td>0.358724</td>\n",
       "      <td>0.621507</td>\n",
       "      <td>0.429667</td>\n",
       "      <td>0.484227</td>\n",
       "      <td>0.300934</td>\n",
       "      <td>0.278332</td>\n",
       "      <td>197.838269</td>\n",
       "      <td>0.107411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.093248</td>\n",
       "      <td>-12.114213</td>\n",
       "      <td>-5.694973</td>\n",
       "      <td>-4.657545</td>\n",
       "      <td>-6.631951</td>\n",
       "      <td>-3.498447</td>\n",
       "      <td>-4.925568</td>\n",
       "      <td>-7.494658</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.134608</td>\n",
       "      <td>-2.776923</td>\n",
       "      <td>-3.553381</td>\n",
       "      <td>-1.867208</td>\n",
       "      <td>-1.389079</td>\n",
       "      <td>-1.243924</td>\n",
       "      <td>-2.377933</td>\n",
       "      <td>-2.735623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>126.500000</td>\n",
       "      <td>-0.896416</td>\n",
       "      <td>-0.174684</td>\n",
       "      <td>0.308677</td>\n",
       "      <td>-0.460058</td>\n",
       "      <td>-0.534567</td>\n",
       "      <td>-0.630717</td>\n",
       "      <td>-0.296289</td>\n",
       "      <td>-0.167880</td>\n",
       "      <td>-0.517068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213746</td>\n",
       "      <td>-0.525289</td>\n",
       "      <td>-0.176915</td>\n",
       "      <td>-0.379766</td>\n",
       "      <td>-0.166227</td>\n",
       "      <td>-0.313631</td>\n",
       "      <td>-0.047868</td>\n",
       "      <td>-0.033083</td>\n",
       "      <td>5.987500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>282.000000</td>\n",
       "      <td>-0.382618</td>\n",
       "      <td>0.285843</td>\n",
       "      <td>0.905435</td>\n",
       "      <td>0.395919</td>\n",
       "      <td>-0.116612</td>\n",
       "      <td>-0.109581</td>\n",
       "      <td>0.116329</td>\n",
       "      <td>0.034755</td>\n",
       "      <td>-0.082270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075802</td>\n",
       "      <td>-0.076551</td>\n",
       "      <td>-0.048353</td>\n",
       "      <td>0.091886</td>\n",
       "      <td>0.143723</td>\n",
       "      <td>-0.026414</td>\n",
       "      <td>0.023199</td>\n",
       "      <td>0.021034</td>\n",
       "      <td>16.665000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>432.000000</td>\n",
       "      <td>1.110739</td>\n",
       "      <td>0.885745</td>\n",
       "      <td>1.532969</td>\n",
       "      <td>1.117559</td>\n",
       "      <td>0.452818</td>\n",
       "      <td>0.482972</td>\n",
       "      <td>0.575390</td>\n",
       "      <td>0.252395</td>\n",
       "      <td>0.412261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095149</td>\n",
       "      <td>0.307438</td>\n",
       "      <td>0.070085</td>\n",
       "      <td>0.426339</td>\n",
       "      <td>0.425798</td>\n",
       "      <td>0.260408</td>\n",
       "      <td>0.112199</td>\n",
       "      <td>0.087023</td>\n",
       "      <td>55.527500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>581.000000</td>\n",
       "      <td>1.586093</td>\n",
       "      <td>5.267376</td>\n",
       "      <td>3.772857</td>\n",
       "      <td>4.075817</td>\n",
       "      <td>7.672544</td>\n",
       "      <td>5.122103</td>\n",
       "      <td>4.808426</td>\n",
       "      <td>2.134599</td>\n",
       "      <td>5.459274</td>\n",
       "      <td>...</td>\n",
       "      <td>5.273420</td>\n",
       "      <td>1.574750</td>\n",
       "      <td>3.150413</td>\n",
       "      <td>1.215279</td>\n",
       "      <td>1.136720</td>\n",
       "      <td>3.087444</td>\n",
       "      <td>2.490503</td>\n",
       "      <td>1.575380</td>\n",
       "      <td>3828.040000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time          V1          V2          V3          V4          V5  \\\n",
       "count  772.000000  772.000000  772.000000  772.000000  772.000000  772.000000   \n",
       "mean   283.005181   -0.176963    0.217169    0.875172    0.285628   -0.005029   \n",
       "std    171.834196    1.294724    1.173401    1.031878    1.258758    1.098143   \n",
       "min      0.000000   -6.093248  -12.114213   -5.694973   -4.657545   -6.631951   \n",
       "25%    126.500000   -0.896416   -0.174684    0.308677   -0.460058   -0.534567   \n",
       "50%    282.000000   -0.382618    0.285843    0.905435    0.395919   -0.116612   \n",
       "75%    432.000000    1.110739    0.885745    1.532969    1.117559    0.452818   \n",
       "max    581.000000    1.586093    5.267376    3.772857    4.075817    7.672544   \n",
       "\n",
       "               V6          V7          V8          V9  ...         V21  \\\n",
       "count  772.000000  772.000000  772.000000  772.000000  ...  772.000000   \n",
       "mean     0.159081    0.123329   -0.057547   -0.030384  ...    0.004888   \n",
       "std      1.225682    0.852075    0.830144    0.878183  ...    0.609335   \n",
       "min     -3.498447   -4.925568   -7.494658   -2.770089  ...   -4.134608   \n",
       "25%     -0.630717   -0.296289   -0.167880   -0.517068  ...   -0.213746   \n",
       "50%     -0.109581    0.116329    0.034755   -0.082270  ...   -0.075802   \n",
       "75%      0.482972    0.575390    0.252395    0.412261  ...    0.095149   \n",
       "max      5.122103    4.808426    2.134599    5.459274  ...    5.273420   \n",
       "\n",
       "              V22         V23         V24         V25         V26         V27  \\\n",
       "count  772.000000  772.000000  772.000000  772.000000  772.000000  772.000000   \n",
       "mean    -0.096995   -0.040344   -0.002501    0.114337    0.022782    0.023353   \n",
       "std      0.607228    0.358724    0.621507    0.429667    0.484227    0.300934   \n",
       "min     -2.776923   -3.553381   -1.867208   -1.389079   -1.243924   -2.377933   \n",
       "25%     -0.525289   -0.176915   -0.379766   -0.166227   -0.313631   -0.047868   \n",
       "50%     -0.076551   -0.048353    0.091886    0.143723   -0.026414    0.023199   \n",
       "75%      0.307438    0.070085    0.426339    0.425798    0.260408    0.112199   \n",
       "max      1.574750    3.150413    1.215279    1.136720    3.087444    2.490503   \n",
       "\n",
       "              V28       Amount       Class  \n",
       "count  772.000000   772.000000  772.000000  \n",
       "mean    -0.017045    68.668290    0.011658  \n",
       "std      0.278332   197.838269    0.107411  \n",
       "min     -2.735623     0.000000    0.000000  \n",
       "25%     -0.033083     5.987500    0.000000  \n",
       "50%      0.021034    16.665000    0.000000  \n",
       "75%      0.087023    55.527500    0.000000  \n",
       "max      1.575380  3828.040000    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab576ca",
   "metadata": {},
   "source": [
    "## stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3de63da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s3_0=x_smote[y_smote.iloc[:]==0]\n",
    "x_s3_1=x_smote[y_smote.iloc[:]==1]\n",
    "y_s3_0=y_smote[y_smote.iloc[:]==0]\n",
    "y_s3_1=y_smote[y_smote.iloc[:]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ad66e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of data points to sample\n",
    "num_samples = 50\n",
    "\n",
    "# Sample the data points from x_s3_0 and x_s3_1 and combine using concat\n",
    "x_s3 = pd.concat([x_s3_0.sample(num_samples, random_state=42), x_s3_1.sample(num_samples, random_state=42)])\n",
    "\n",
    "# Sample the labels from y_s3_0 and y_s3_1 and combine using concat\n",
    "y_s3 = pd.concat([y_s3_0.sample(num_samples, random_state=42), y_s3_1.sample(num_samples, random_state=42)])\n",
    "#This code sets the number of data points to sample,\n",
    "#samples the data points from x_s3_0 and x_s3_1 using the sample() method, \n",
    "#combines the sampled data points using concat(), and assigns them to x_s3. \n",
    "#Similarly, it samples the labels from y_s3_0 and y_s3_1, \n",
    "#combines the sampled labels using concat(), and assigns them to y_s3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4231531",
   "metadata": {},
   "source": [
    "## clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "df314c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    cs = []\n",
    "    for i in range(1, 21):\n",
    "        kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "        kmeans.fit(x_smote)\n",
    "        cs.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1, 21), cs)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('No. of clusters')\n",
    "plt.ylabel('CS')\n",
    "plt.show()\n",
    "#This code initializes an empty list to store the cluster sum of squares, \n",
    "#loops through the number of clusters from 1 to 20, \n",
    "#initializes a KMeans model with the current number of clusters,\n",
    "#fits the KMeans model to the data, appends the cluster sum of squares to the list, and plots the results using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fdfeaacd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V22       V23       V24       V25       V26  \\\n",
      "0  0.098698  0.363787  ...  0.277838 -0.110474  0.066928  0.128539 -0.189115   \n",
      "1  0.085102 -0.255425  ... -0.638672  0.101288 -0.339846  0.167170  0.125895   \n",
      "2  0.247676 -1.514654  ...  0.771679  0.909412 -0.689281 -0.327642 -0.139097   \n",
      "3  0.377436 -1.387024  ...  0.005274 -0.190321 -1.175575  0.647376 -0.221929   \n",
      "4 -0.270533  0.817739  ...  0.798278 -0.137458  0.141267 -0.206010  0.502292   \n",
      "\n",
      "        V27       V28  Amount  Class  Cluster  \n",
      "0  0.133558 -0.021053  149.62      0        8  \n",
      "1 -0.008983  0.014724    2.69      1       13  \n",
      "2 -0.055353 -0.059752  378.66      0        4  \n",
      "3  0.062723  0.061458  123.50      0       13  \n",
      "4  0.219422  0.215153   69.99      0       13  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# set the number of clusters\n",
    "n_clusters = 14\n",
    "kmeans = KMeans(n_clusters=n_clusters,random_state=42)\n",
    "\n",
    "# fit the model to the data\n",
    "kmeans.fit(data)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# appending \"cluster\" to the dataset\n",
    "cluster_data = pd.DataFrame({'Cluster': labels})\n",
    "\n",
    "clustered_data = pd.concat([data, cluster_data], axis=1)\n",
    "\n",
    "print(clustered_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0a321210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>575</td>\n",
       "      <td>-0.572263</td>\n",
       "      <td>0.731748</td>\n",
       "      <td>1.541254</td>\n",
       "      <td>0.150506</td>\n",
       "      <td>1.108974</td>\n",
       "      <td>0.372152</td>\n",
       "      <td>1.084879</td>\n",
       "      <td>-0.146329</td>\n",
       "      <td>-0.274447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107582</td>\n",
       "      <td>-0.418263</td>\n",
       "      <td>-0.731029</td>\n",
       "      <td>0.877525</td>\n",
       "      <td>-0.364150</td>\n",
       "      <td>-0.177509</td>\n",
       "      <td>-0.256545</td>\n",
       "      <td>26.72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>579</td>\n",
       "      <td>-1.296845</td>\n",
       "      <td>-0.511605</td>\n",
       "      <td>2.404726</td>\n",
       "      <td>-0.310762</td>\n",
       "      <td>-0.319551</td>\n",
       "      <td>-0.542842</td>\n",
       "      <td>-0.173310</td>\n",
       "      <td>0.260423</td>\n",
       "      <td>-1.202688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161175</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.285390</td>\n",
       "      <td>0.281069</td>\n",
       "      <td>-0.370130</td>\n",
       "      <td>0.043410</td>\n",
       "      <td>0.092318</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>579</td>\n",
       "      <td>1.214170</td>\n",
       "      <td>0.210481</td>\n",
       "      <td>0.484651</td>\n",
       "      <td>0.479768</td>\n",
       "      <td>-0.261955</td>\n",
       "      <td>-0.527039</td>\n",
       "      <td>0.021782</td>\n",
       "      <td>-0.106888</td>\n",
       "      <td>-0.037631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.594609</td>\n",
       "      <td>0.159877</td>\n",
       "      <td>0.091873</td>\n",
       "      <td>0.140964</td>\n",
       "      <td>0.227406</td>\n",
       "      <td>-0.017389</td>\n",
       "      <td>0.016030</td>\n",
       "      <td>5.98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>580</td>\n",
       "      <td>1.267030</td>\n",
       "      <td>-0.071114</td>\n",
       "      <td>0.037680</td>\n",
       "      <td>0.512683</td>\n",
       "      <td>0.242392</td>\n",
       "      <td>0.705212</td>\n",
       "      <td>-0.226582</td>\n",
       "      <td>0.109483</td>\n",
       "      <td>0.657565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177225</td>\n",
       "      <td>-0.222918</td>\n",
       "      <td>-1.245505</td>\n",
       "      <td>0.678360</td>\n",
       "      <td>0.525059</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>12.36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>581</td>\n",
       "      <td>1.153758</td>\n",
       "      <td>0.132273</td>\n",
       "      <td>0.382969</td>\n",
       "      <td>1.405063</td>\n",
       "      <td>-0.224287</td>\n",
       "      <td>-0.197295</td>\n",
       "      <td>0.020653</td>\n",
       "      <td>0.029260</td>\n",
       "      <td>0.412254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125231</td>\n",
       "      <td>-0.057041</td>\n",
       "      <td>0.073082</td>\n",
       "      <td>0.633977</td>\n",
       "      <td>-0.310685</td>\n",
       "      <td>0.033590</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>13.79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>772 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0       0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1       0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "767   575 -0.572263  0.731748  1.541254  0.150506  1.108974  0.372152   \n",
       "768   579 -1.296845 -0.511605  2.404726 -0.310762 -0.319551 -0.542842   \n",
       "769   579  1.214170  0.210481  0.484651  0.479768 -0.261955 -0.527039   \n",
       "770   580  1.267030 -0.071114  0.037680  0.512683  0.242392  0.705212   \n",
       "771   581  1.153758  0.132273  0.382969  1.405063 -0.224287 -0.197295   \n",
       "\n",
       "           V7        V8        V9  ...       V22       V23       V24  \\\n",
       "0    0.239599  0.098698  0.363787  ...  0.277838 -0.110474  0.066928   \n",
       "1   -0.078803  0.085102 -0.255425  ... -0.638672  0.101288 -0.339846   \n",
       "2    0.791461  0.247676 -1.514654  ...  0.771679  0.909412 -0.689281   \n",
       "3    0.237609  0.377436 -1.387024  ...  0.005274 -0.190321 -1.175575   \n",
       "4    0.592941 -0.270533  0.817739  ...  0.798278 -0.137458  0.141267   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "767  1.084879 -0.146329 -0.274447  ... -0.107582 -0.418263 -0.731029   \n",
       "768 -0.173310  0.260423 -1.202688  ... -0.161175  0.088496  0.285390   \n",
       "769  0.021782 -0.106888 -0.037631  ... -0.594609  0.159877  0.091873   \n",
       "770 -0.226582  0.109483  0.657565  ... -0.177225 -0.222918 -1.245505   \n",
       "771  0.020653  0.029260  0.412254  ... -0.125231 -0.057041  0.073082   \n",
       "\n",
       "          V25       V26       V27       V28  Amount  Class  Cluster  \n",
       "0    0.128539 -0.189115  0.133558 -0.021053  149.62      0        8  \n",
       "1    0.167170  0.125895 -0.008983  0.014724    2.69      1       13  \n",
       "2   -0.327642 -0.139097 -0.055353 -0.059752  378.66      0        4  \n",
       "3    0.647376 -0.221929  0.062723  0.061458  123.50      0       13  \n",
       "4   -0.206010  0.502292  0.219422  0.215153   69.99      0       13  \n",
       "..        ...       ...       ...       ...     ...    ...      ...  \n",
       "767  0.877525 -0.364150 -0.177509 -0.256545   26.72      0        1  \n",
       "768  0.281069 -0.370130  0.043410  0.092318   80.00      0        1  \n",
       "769  0.140964  0.227406 -0.017389  0.016030    5.98      0        1  \n",
       "770  0.678360  0.525059  0.002920 -0.003333   12.36      0        1  \n",
       "771  0.633977 -0.310685  0.033590  0.015250   13.79      0        1  \n",
       "\n",
       "[772 rows x 32 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2bac902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping data points by their corresponding cluster label by creating an empty dictionary with cluster labels as keys and corresponding data points as values.\n",
    "clusters = {}\n",
    "for i, label in enumerate(labels):\n",
    "    if label not in clusters:\n",
    "        clusters[label] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "05a2d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=list(clusters.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "91aeb902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a dictionary of dataframes, one for each cluster\n",
    "cluster_dfs = {}\n",
    "for i, clustered_data in clustered_data.groupby('Cluster'):\n",
    "    cluster_dfs[i] = pd.DataFrame(clustered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "52e52e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows = []\n",
    "for cluster_label, cluster_df in cluster_dfs.items():\n",
    "    rows = cluster_df.sample(n=10, random_state=42, replace=True)\n",
    "    selected_rows.append(rows)\n",
    "\n",
    "selected_df = pd.concat(selected_rows)\n",
    "#This code first creates an empty list selected_rows to store the selected rows.\n",
    "#Then it uses the items() method to loop through the cluster_dfs dictionary and unpack the key-value pairs into cluster_label and cluster_df variables, respectively.\n",
    "#For each cluster, it uses the sample() method to randomly select 10 rows from the corresponding dataframe,\n",
    "#and then appends the selected rows to the selected_rows list.\n",
    "#Finally, the code uses pd.concat() to concatenate the selected rows in selected_rows into a single dataframe selected_df.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0a0e5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_s4=selected_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ada331eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s4=selected_df[selected_df.columns.drop(\"Cluster\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d7511770",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s4=x_s4[x_s4.columns.drop(\"Class\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5ed4f5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>142</td>\n",
       "      <td>1.211406</td>\n",
       "      <td>0.007850</td>\n",
       "      <td>0.950798</td>\n",
       "      <td>1.137646</td>\n",
       "      <td>-0.495189</td>\n",
       "      <td>0.301371</td>\n",
       "      <td>-0.518350</td>\n",
       "      <td>0.095426</td>\n",
       "      <td>0.817592</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049912</td>\n",
       "      <td>-0.107248</td>\n",
       "      <td>-0.057153</td>\n",
       "      <td>-0.118933</td>\n",
       "      <td>-0.421241</td>\n",
       "      <td>0.556146</td>\n",
       "      <td>-0.360164</td>\n",
       "      <td>0.076930</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>105</td>\n",
       "      <td>1.175094</td>\n",
       "      <td>0.408263</td>\n",
       "      <td>0.552145</td>\n",
       "      <td>1.255068</td>\n",
       "      <td>-0.196662</td>\n",
       "      <td>-0.565605</td>\n",
       "      <td>0.133973</td>\n",
       "      <td>-0.146202</td>\n",
       "      <td>-0.214155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116439</td>\n",
       "      <td>0.130585</td>\n",
       "      <td>0.523640</td>\n",
       "      <td>-0.050125</td>\n",
       "      <td>0.448133</td>\n",
       "      <td>0.597867</td>\n",
       "      <td>-0.275067</td>\n",
       "      <td>0.043308</td>\n",
       "      <td>0.023924</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>162</td>\n",
       "      <td>1.039964</td>\n",
       "      <td>-0.534355</td>\n",
       "      <td>1.865190</td>\n",
       "      <td>1.145122</td>\n",
       "      <td>-1.488133</td>\n",
       "      <td>0.589641</td>\n",
       "      <td>-1.119900</td>\n",
       "      <td>0.382781</td>\n",
       "      <td>1.419160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053880</td>\n",
       "      <td>-0.014701</td>\n",
       "      <td>0.430843</td>\n",
       "      <td>-0.071344</td>\n",
       "      <td>0.638434</td>\n",
       "      <td>0.366778</td>\n",
       "      <td>0.451211</td>\n",
       "      <td>0.053840</td>\n",
       "      <td>0.023451</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>147</td>\n",
       "      <td>-2.687978</td>\n",
       "      <td>4.390230</td>\n",
       "      <td>-2.360483</td>\n",
       "      <td>0.360829</td>\n",
       "      <td>1.310192</td>\n",
       "      <td>-1.645253</td>\n",
       "      <td>2.327776</td>\n",
       "      <td>-1.727825</td>\n",
       "      <td>4.324752</td>\n",
       "      <td>...</td>\n",
       "      <td>3.169344</td>\n",
       "      <td>-1.045961</td>\n",
       "      <td>-0.156951</td>\n",
       "      <td>0.079854</td>\n",
       "      <td>-0.012598</td>\n",
       "      <td>0.207194</td>\n",
       "      <td>-0.536578</td>\n",
       "      <td>0.950393</td>\n",
       "      <td>-0.624431</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>112</td>\n",
       "      <td>1.102698</td>\n",
       "      <td>0.103965</td>\n",
       "      <td>0.934479</td>\n",
       "      <td>1.152704</td>\n",
       "      <td>-0.693597</td>\n",
       "      <td>-0.584580</td>\n",
       "      <td>-0.148439</td>\n",
       "      <td>-0.112031</td>\n",
       "      <td>0.196750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037095</td>\n",
       "      <td>-0.017211</td>\n",
       "      <td>-0.098781</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>0.394412</td>\n",
       "      <td>0.334208</td>\n",
       "      <td>-0.520700</td>\n",
       "      <td>0.045952</td>\n",
       "      <td>0.048005</td>\n",
       "      <td>54.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18</td>\n",
       "      <td>0.247491</td>\n",
       "      <td>0.277666</td>\n",
       "      <td>1.185471</td>\n",
       "      <td>-0.092603</td>\n",
       "      <td>-1.314394</td>\n",
       "      <td>-0.150116</td>\n",
       "      <td>-0.946365</td>\n",
       "      <td>-1.617935</td>\n",
       "      <td>1.544071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230983</td>\n",
       "      <td>1.650180</td>\n",
       "      <td>0.200454</td>\n",
       "      <td>-0.185353</td>\n",
       "      <td>0.423073</td>\n",
       "      <td>0.820591</td>\n",
       "      <td>-0.227632</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>0.250475</td>\n",
       "      <td>22.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>74</td>\n",
       "      <td>1.038370</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.184456</td>\n",
       "      <td>1.109950</td>\n",
       "      <td>0.441699</td>\n",
       "      <td>0.945283</td>\n",
       "      <td>-0.036715</td>\n",
       "      <td>0.350995</td>\n",
       "      <td>0.118950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.335520</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>0.605089</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>-0.626463</td>\n",
       "      <td>0.479120</td>\n",
       "      <td>-0.166937</td>\n",
       "      <td>0.081247</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>83</td>\n",
       "      <td>-1.864990</td>\n",
       "      <td>0.910874</td>\n",
       "      <td>1.724863</td>\n",
       "      <td>-1.748371</td>\n",
       "      <td>0.578943</td>\n",
       "      <td>-0.832531</td>\n",
       "      <td>1.901440</td>\n",
       "      <td>-1.913986</td>\n",
       "      <td>2.112375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274877</td>\n",
       "      <td>-0.318597</td>\n",
       "      <td>0.073323</td>\n",
       "      <td>-0.061693</td>\n",
       "      <td>0.547204</td>\n",
       "      <td>-0.466798</td>\n",
       "      <td>0.408030</td>\n",
       "      <td>-2.377933</td>\n",
       "      <td>-1.255549</td>\n",
       "      <td>7.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>52</td>\n",
       "      <td>1.147369</td>\n",
       "      <td>0.059035</td>\n",
       "      <td>0.263632</td>\n",
       "      <td>1.211023</td>\n",
       "      <td>-0.044096</td>\n",
       "      <td>0.301067</td>\n",
       "      <td>-0.132960</td>\n",
       "      <td>0.227885</td>\n",
       "      <td>0.252191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255924</td>\n",
       "      <td>-0.087813</td>\n",
       "      <td>-0.110756</td>\n",
       "      <td>-0.097771</td>\n",
       "      <td>-0.323374</td>\n",
       "      <td>0.633279</td>\n",
       "      <td>-0.305328</td>\n",
       "      <td>0.027394</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>6.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>67</td>\n",
       "      <td>-0.653445</td>\n",
       "      <td>0.160225</td>\n",
       "      <td>1.592256</td>\n",
       "      <td>1.296832</td>\n",
       "      <td>0.997175</td>\n",
       "      <td>-0.343000</td>\n",
       "      <td>0.469937</td>\n",
       "      <td>-0.132470</td>\n",
       "      <td>-0.197794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225920</td>\n",
       "      <td>0.038363</td>\n",
       "      <td>0.336449</td>\n",
       "      <td>-0.014883</td>\n",
       "      <td>0.102959</td>\n",
       "      <td>-0.265322</td>\n",
       "      <td>-0.348637</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>-0.049478</td>\n",
       "      <td>19.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "215   142  1.211406  0.007850  0.950798  1.137646 -0.495189  0.301371   \n",
       "166   105  1.175094  0.408263  0.552145  1.255068 -0.196662 -0.565605   \n",
       "241   162  1.039964 -0.534355  1.865190  1.145122 -1.488133  0.589641   \n",
       "225   147 -2.687978  4.390230 -2.360483  0.360829  1.310192 -1.645253   \n",
       "175   112  1.102698  0.103965  0.934479  1.152704 -0.693597 -0.584580   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "23     18  0.247491  0.277666  1.185471 -0.092603 -1.314394 -0.150116   \n",
       "113    74  1.038370  0.127486  0.184456  1.109950  0.441699  0.945283   \n",
       "132    83 -1.864990  0.910874  1.724863 -1.748371  0.578943 -0.832531   \n",
       "81     52  1.147369  0.059035  0.263632  1.211023 -0.044096  0.301067   \n",
       "97     67 -0.653445  0.160225  1.592256  1.296832  0.997175 -0.343000   \n",
       "\n",
       "           V7        V8        V9  ...       V20       V21       V22  \\\n",
       "215 -0.518350  0.095426  0.817592  ... -0.049912 -0.107248 -0.057153   \n",
       "166  0.133973 -0.146202 -0.214155  ... -0.116439  0.130585  0.523640   \n",
       "241 -1.119900  0.382781  1.419160  ... -0.053880 -0.014701  0.430843   \n",
       "225  2.327776 -1.727825  4.324752  ...  3.169344 -1.045961 -0.156951   \n",
       "175 -0.148439 -0.112031  0.196750  ...  0.037095 -0.017211 -0.098781   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "23  -0.946365 -1.617935  1.544071  ... -0.230983  1.650180  0.200454   \n",
       "113 -0.036715  0.350995  0.118950  ... -0.335520  0.102520  0.605089   \n",
       "132  1.901440 -1.913986  2.112375  ...  0.274877 -0.318597  0.073323   \n",
       "81  -0.132960  0.227885  0.252191  ... -0.255924 -0.087813 -0.110756   \n",
       "97   0.469937 -0.132470 -0.197794  ...  0.225920  0.038363  0.336449   \n",
       "\n",
       "          V23       V24       V25       V26       V27       V28  Amount  \n",
       "215 -0.118933 -0.421241  0.556146 -0.360164  0.076930  0.031800    9.99  \n",
       "166 -0.050125  0.448133  0.597867 -0.275067  0.043308  0.023924    1.00  \n",
       "241 -0.071344  0.638434  0.366778  0.451211  0.053840  0.023451   22.00  \n",
       "225  0.079854 -0.012598  0.207194 -0.536578  0.950393 -0.624431    0.89  \n",
       "175  0.003331  0.394412  0.334208 -0.520700  0.045952  0.048005   54.99  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "23  -0.185353  0.423073  0.820591 -0.227632  0.336634  0.250475   22.75  \n",
       "113  0.023092 -0.626463  0.479120 -0.166937  0.081247  0.001192    1.18  \n",
       "132 -0.061693  0.547204 -0.466798  0.408030 -2.377933 -1.255549    7.69  \n",
       "81  -0.097771 -0.323374  0.633279 -0.305328  0.027394 -0.000580    6.67  \n",
       "97  -0.014883  0.102959 -0.265322 -0.348637  0.011238 -0.049478   19.85  \n",
       "\n",
       "[140 rows x 30 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "04962d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "nm = NearMiss()\n",
    "x_s5, y_s5 = nm.fit_resample(X, y)\n",
    "\n",
    "# Perform SMOTE oversampling on the undersampled data\n",
    "smote = SMOTE()\n",
    "x_s5, y_s5 = smote.fit_resample(x_s5, y_s5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ad56a3",
   "metadata": {},
   "source": [
    "# Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d77de",
   "metadata": {},
   "source": [
    "#### Model - 1 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "ce8343c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "b138637f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6664482306684142]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## sample 1 using SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create an SVM classifier object\n",
    "m1 = SVC()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "m1.fit(x_s1, y_s1)\n",
    "\n",
    "# Use the classifier to make predictions on the test data\n",
    "y_pred_m1_s1 = m1.predict(x_smote)\n",
    "\n",
    "# Evaluate the classifier's accuracy using metrics like accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "m1_acc.append(accuracy_score(y_smote, y_pred_m1_s1))\n",
    "m1_acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "b598e8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6664482306684142, 0.663826998689384]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##sample 2\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create an SVM classifier object\n",
    "m1 = SVC()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "m1.fit(x_s2, y_s2)\n",
    "\n",
    "# Use the classifier to make predictions on the test data\n",
    "y_pred_m1_s2 = m1.predict(x_smote)\n",
    "\n",
    "# Evaluate the classifier's accuracy using metrics like accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "m1_acc.append(accuracy_score(y_smote, y_pred_m1_s2))\n",
    "m1_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "ea06b692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6664482306684142, 0.663826998689384, 0.6480996068152032]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##sample 3\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create an SVM classifier object\n",
    "m1 = SVC()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "m1.fit(x_s3, y_s3)\n",
    "\n",
    "# Use the classifier to make predictions on the test data\n",
    "y_pred_m1_s3 = m1.predict(x_smote)\n",
    "\n",
    "# Evaluate the classifier's accuracy using metrics like accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "m1_acc.append(accuracy_score(y_smote, y_pred_m1_s3))\n",
    "m1_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "9f927e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6664482306684142, 0.663826998689384, 0.6480996068152032, 0.5]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##sample 4\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create an SVM classifier object\n",
    "m1 = SVC()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "m1.fit(x_s4, y_s4)\n",
    "\n",
    "# Use the classifier to make predictions on the test data\n",
    "y_pred_m1_s4 = m1.predict(x_smote)\n",
    "\n",
    "# Evaluate the classifier's accuracy using metrics like accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "m1_acc.append(accuracy_score(y_smote, y_pred_m1_s4))\n",
    "m1_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "9fcd295f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6664482306684142,\n",
       " 0.663826998689384,\n",
       " 0.6480996068152032,\n",
       " 0.5,\n",
       " 0.35714285714285715]"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##sample 5\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create an SVM classifier object\n",
    "m1 = SVC()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "m1.fit(x_s5, y_s5)\n",
    "\n",
    "# Use the classifier to make predictions on the test data\n",
    "y_pred_m1_s5 = m1.predict(x_smote)\n",
    "\n",
    "# Evaluate the classifier's accuracy using metrics like accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "m1_acc.append(accuracy_score(y_smote, y_pred_m1_s5))\n",
    "m1_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ec2d51",
   "metadata": {},
   "source": [
    "#### Model - 2 Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "2571bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "a0c69732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8551769331585846]"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample 1\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a Naive Bayes classifier object\n",
    "m2 = GaussianNB()\n",
    "m2.fit(x_s1, y_s1)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m2.predict(x_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m2_acc.append(m2.score(x_smote, y_smote))\n",
    "m2_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "fe689b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8551769331585846, 0.7706422018348624]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample 2\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a Naive Bayes classifier object\n",
    "m2 = GaussianNB()\n",
    "m2.fit(x_s2, y_s2)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m2.predict(x_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m2_acc.append(m2.score(x_smote, y_smote))\n",
    "m2_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "8dfba07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8551769331585846, 0.7706422018348624, 0.7667103538663171]"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smaple 3\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a Naive Bayes classifier object\n",
    "m2 = GaussianNB()\n",
    "m2.fit(x_s3, y_s3)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m2.predict(x_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m2_acc.append(m2.score(x_smote, y_smote))\n",
    "m2_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "0982ca9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8551769331585846,\n",
       " 0.7706422018348624,\n",
       " 0.7667103538663171,\n",
       " 0.6369593709043251]"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 4\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a Naive Bayes classifier object\n",
    "m2 = GaussianNB()\n",
    "m2.fit(x_s4, y_s4)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m2.predict(x_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m2_acc.append(m2.score(x_smote, y_smote))\n",
    "m2_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "eb3da7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8551769331585846,\n",
       " 0.7706422018348624,\n",
       " 0.7667103538663171,\n",
       " 0.6369593709043251,\n",
       " 0.4305373525557012]"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 5\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a Naive Bayes classifier object\n",
    "m2 = GaussianNB()\n",
    "m2.fit(x_s5, y_s5)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m2.predict(x_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m2_acc.append(m2.score(x_smote, y_smote))\n",
    "m2_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35323483",
   "metadata": {},
   "source": [
    "#### Model - 3 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "7307892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "719db4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9737876802096985]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 1\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a Gradient Boosting Classifier object\n",
    "m3 = GradientBoostingClassifier()\n",
    "m3.fit(x_s1, y_s1)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m3.predict(x_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m3_acc.append(m3.score(x_smote, y_smote))\n",
    "m3_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "56b23b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9737876802096985, 0.9639580602883355]"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a Gradient Boosting Classifier object\n",
    "m3 = GradientBoostingClassifier()\n",
    "m3.fit(x_s2, y_s2)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m3.predict(x_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m3_acc.append(m3.score(x_smote, y_smote))\n",
    "m3_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "3bbf1537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9737876802096985, 0.9639580602883355, 0.9246395806028833]"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 3\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a Gradient Boosting Classifier object\n",
    "m3 = GradientBoostingClassifier()\n",
    "m3.fit(x_s3, y_s3)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m3.predict(x_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m3_acc.append(m3.score(x_smote, y_smote))\n",
    "m3_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "8b775b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9737876802096985,\n",
       " 0.9639580602883355,\n",
       " 0.9246395806028833,\n",
       " 0.5013106159895151]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 4\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a Gradient Boosting Classifier object\n",
    "m3 = GradientBoostingClassifier()\n",
    "m3.fit(x_s4, y_s4)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m3.predict(x_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m3_acc.append(m3.score(x_smote, y_smote))\n",
    "m3_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "d1484df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9737876802096985,\n",
       " 0.9639580602883355,\n",
       " 0.9246395806028833,\n",
       " 0.5013106159895151,\n",
       " 0.4750982961992136]"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 5\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a Gradient Boosting Classifier object\n",
    "m3 = GradientBoostingClassifier()\n",
    "m3.fit(x_s5, y_s5)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m3.predict(x_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m3_acc.append(m3.score(x_smote, y_smote))\n",
    "m3_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51a562",
   "metadata": {},
   "source": [
    "#### Model - 4 XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "99fd0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "a44e7e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\ikshit\\anaconda3\\lib\\site-packages (1.7.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\ikshit\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\ikshit\\anaconda3\\lib\\site-packages (from xgboost) (1.9.1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9488859764089121]"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 1\n",
    "!pip install xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the hyperparameters for the model\n",
    "#param = {'max_depth': 3, 'eta': 0.1, 'objective': 'multi:softmax', 'num_class': 3}\n",
    "\n",
    "# Train the model\n",
    "#model = xgb.XGBClassifier(params=param,num_boost_round=10)\n",
    "model4 = xgb.XGBClassifier(max_depth=10, eta=0.5, objective='multi:softmax', num_class=2, n_estimators=100)\n",
    "\n",
    "model4.fit(x_s1,y_s1)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model4.predict(x_smote)\n",
    "m4_acc.append(accuracy_score(y_smote, y_pred))\n",
    "m4_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "f32e7672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9488859764089121, 0.944954128440367]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 2\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the hyperparameters for the model\n",
    "#param = {'max_depth': 3, 'eta': 0.1, 'objective': 'multi:softmax', 'num_class': 3}\n",
    "\n",
    "# Train the model\n",
    "#model = xgb.XGBClassifier(params=param,num_boost_round=10)\n",
    "model4 = xgb.XGBClassifier(max_depth=10, eta=0.5, objective='multi:softmax', num_class=2, n_estimators=10)\n",
    "\n",
    "model4.fit(x_s2,y_s2)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model4.predict(x_smote)\n",
    "m4_acc.append(accuracy_score(y_smote, y_pred))\n",
    "m4_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "ff10255f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9488859764089121, 0.944954128440367, 0.9292267365661862]"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 3\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the hyperparameters for the model\n",
    "#param = {'max_depth': 3, 'eta': 0.1, 'objective': 'multi:softmax', 'num_class': 3}\n",
    "\n",
    "# Train the model\n",
    "#model = xgb.XGBClassifier(params=param,num_boost_round=10)\n",
    "model4 = xgb.XGBClassifier(max_depth=10, eta=0.5, objective='multi:softmax', num_class=2, n_estimators=10)\n",
    "\n",
    "model4.fit(x_s3,y_s3)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model4.predict(x_smote)\n",
    "m4_acc.append(accuracy_score(y_smote, y_pred))\n",
    "m4_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "f16c688a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9488859764089121, 0.944954128440367, 0.9292267365661862, 0.5150720838794234]"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 4\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the hyperparameters for the model\n",
    "#param = {'max_depth': 3, 'eta': 0.1, 'objective': 'multi:softmax', 'num_class': 3}\n",
    "\n",
    "# Train the model\n",
    "#model = xgb.XGBClassifier(params=param,num_boost_round=10)\n",
    "model4 = xgb.XGBClassifier(max_depth=10, eta=0.5, objective='multi:softmax', num_class=2, n_estimators=10)\n",
    "\n",
    "model4.fit(x_s4,y_s4)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model4.predict(x_smote)\n",
    "m4_acc.append(accuracy_score(y_smote, y_pred))\n",
    "m4_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "fb7c5560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9488859764089121,\n",
       " 0.944954128440367,\n",
       " 0.9292267365661862,\n",
       " 0.5150720838794234,\n",
       " 0.4947575360419397]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 5\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the hyperparameters for the model\n",
    "#param = {'max_depth': 3, 'eta': 0.1, 'objective': 'multi:softmax', 'num_class': 3}\n",
    "\n",
    "# Train the model\n",
    "#model = xgb.XGBClassifier(params=param,num_boost_round=10)\n",
    "model4 = xgb.XGBClassifier(max_depth=10, eta=0.5, objective='multi:softmax', num_class=2, n_estimators=10)\n",
    "\n",
    "model4.fit(x_s5,y_s5)\n",
    "\n",
    "# accuracy_score(y_smote, y_pred)\n",
    "# Make predictions on the test set\n",
    "y_pred = model4.predict(x_smote)\n",
    "m4_acc.append(accuracy_score(y_smote, y_pred))\n",
    "m4_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0401a8",
   "metadata": {},
   "source": [
    "#### Model - 5 StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "0471748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m5_acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "59b76b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5124508519003932]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample 1\n",
    "\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Define the base models\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('gb', GradientBoostingClassifier())\n",
    "]\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = MLPClassifier(max_iter=3000)\n",
    "\n",
    "# Create the stacking classifier\n",
    "m5 = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=meta_model, cv=5\n",
    ")\n",
    "\n",
    "# Suppress UserWarnings\n",
    "warnings.simplefilter('ignore', category=UserWarning)\n",
    "\n",
    "# Fit the stacking classifier to the training data\n",
    "m5.fit(x_s4, y_s4)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m5.predict(x_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m5_acc.append(m5.score(x_smote, y_smote))\n",
    "m5_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "c1abc51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5124508519003932, 0.9868938401048493]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample2\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Define the base models\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('gb', GradientBoostingClassifier())\n",
    "]\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = MLPClassifier(max_iter=3000)\n",
    "\n",
    "# Create the stacking classifier\n",
    "m5 = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=meta_model, cv=5\n",
    ")\n",
    "\n",
    "# Suppress UserWarnings\n",
    "warnings.simplefilter('ignore', category=UserWarning)\n",
    "\n",
    "# Fit the stacking classifier to the training data\n",
    "m5.fit(x_s2, y_s2)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m5.predict(x_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m5_acc.append(m5.score(x_smote, y_smote))\n",
    "m5_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "6a8bd8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5124508519003932, 0.9868938401048493, 0.9469200524246396]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample3\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Define the base models\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('gb', GradientBoostingClassifier())\n",
    "]\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = MLPClassifier(max_iter=3000)\n",
    "\n",
    "# Create the stacking classifier\n",
    "m5 = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=meta_model, cv=5\n",
    ")\n",
    "\n",
    "# Suppress UserWarnings\n",
    "warnings.simplefilter('ignore', category=UserWarning)\n",
    "\n",
    "# Fit the stacking classifier to the training data\n",
    "m5.fit(x_s3, y_s3)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m5.predict(x_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m5_acc.append(m5.score(x_smote, y_smote))\n",
    "m5_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "a7c90e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5124508519003932,\n",
       " 0.9868938401048493,\n",
       " 0.9469200524246396,\n",
       " 0.5072083879423329]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample4\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Define the base models\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('gb', GradientBoostingClassifier())\n",
    "]\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = MLPClassifier(max_iter=3000)\n",
    "\n",
    "# Create the stacking classifier\n",
    "m5 = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=meta_model, cv=5\n",
    ")\n",
    "\n",
    "# Suppress UserWarnings\n",
    "warnings.simplefilter('ignore', category=UserWarning)\n",
    "\n",
    "# Fit the stacking classifier to the training data\n",
    "m5.fit(x_s4, y_s4)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m5.predict(x_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m5_acc.append(m5.score(x_smote, y_smote))\n",
    "m5_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "43a445fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5124508519003932,\n",
       " 0.9868938401048493,\n",
       " 0.9469200524246396,\n",
       " 0.5072083879423329,\n",
       " 0.3617300131061599]"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample5\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Define the base models\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('gb', GradientBoostingClassifier())\n",
    "]\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = MLPClassifier(max_iter=3000)\n",
    "\n",
    "# Create the stacking classifier\n",
    "m5 = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=meta_model, cv=5\n",
    ")\n",
    "\n",
    "# Suppress UserWarnings\n",
    "warnings.simplefilter('ignore', category=UserWarning)\n",
    "\n",
    "# Fit the stacking classifier to the training data\n",
    "m5.fit(x_s5, y_s5)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = m5.predict(x_smote)\n",
    "# m5.score(x_smote, y_smote)\n",
    "\n",
    "# evaluate the model\n",
    "m5_acc.append(m5.score(x_smote, y_smote))\n",
    "m5_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24320cf6",
   "metadata": {},
   "source": [
    "# Comparing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "26e3e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp=pd.DataFrame(data=[m1_acc,m2_acc,m3_acc,m4_acc,m5_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "c32364ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666448</td>\n",
       "      <td>0.663827</td>\n",
       "      <td>0.648100</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.855177</td>\n",
       "      <td>0.770642</td>\n",
       "      <td>0.766710</td>\n",
       "      <td>0.636959</td>\n",
       "      <td>0.430537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.973788</td>\n",
       "      <td>0.963958</td>\n",
       "      <td>0.924640</td>\n",
       "      <td>0.501311</td>\n",
       "      <td>0.475098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.948886</td>\n",
       "      <td>0.944954</td>\n",
       "      <td>0.929227</td>\n",
       "      <td>0.515072</td>\n",
       "      <td>0.494758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.512451</td>\n",
       "      <td>0.986894</td>\n",
       "      <td>0.946920</td>\n",
       "      <td>0.507208</td>\n",
       "      <td>0.361730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4\n",
       "0  0.666448  0.663827  0.648100  0.500000  0.357143\n",
       "1  0.855177  0.770642  0.766710  0.636959  0.430537\n",
       "2  0.973788  0.963958  0.924640  0.501311  0.475098\n",
       "3  0.948886  0.944954  0.929227  0.515072  0.494758\n",
       "4  0.512451  0.986894  0.946920  0.507208  0.361730"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "02947a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp.index=[\"SVM\",\"Naive Bayes classifier\",\"Gradient Boosting\",\"XGboost\",\"StackingClassifier\"]\n",
    "comp.columns=[\"Random\",\"Systematic\",\"Stratified\",\"Clustering\",\"NearMiss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "dcf2054f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random</th>\n",
       "      <th>Systematic</th>\n",
       "      <th>Stratified</th>\n",
       "      <th>Clustering</th>\n",
       "      <th>NearMiss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.666448</td>\n",
       "      <td>0.663827</td>\n",
       "      <td>0.648100</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes classifier</th>\n",
       "      <td>0.855177</td>\n",
       "      <td>0.770642</td>\n",
       "      <td>0.766710</td>\n",
       "      <td>0.636959</td>\n",
       "      <td>0.430537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.973788</td>\n",
       "      <td>0.963958</td>\n",
       "      <td>0.924640</td>\n",
       "      <td>0.501311</td>\n",
       "      <td>0.475098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGboost</th>\n",
       "      <td>0.948886</td>\n",
       "      <td>0.944954</td>\n",
       "      <td>0.929227</td>\n",
       "      <td>0.515072</td>\n",
       "      <td>0.494758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StackingClassifier</th>\n",
       "      <td>0.512451</td>\n",
       "      <td>0.986894</td>\n",
       "      <td>0.946920</td>\n",
       "      <td>0.507208</td>\n",
       "      <td>0.361730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Random  Systematic  Stratified  Clustering  NearMiss\n",
       "SVM                     0.666448    0.663827    0.648100    0.500000  0.357143\n",
       "Naive Bayes classifier  0.855177    0.770642    0.766710    0.636959  0.430537\n",
       "Gradient Boosting       0.973788    0.963958    0.924640    0.501311  0.475098\n",
       "XGboost                 0.948886    0.944954    0.929227    0.515072  0.494758\n",
       "StackingClassifier      0.512451    0.986894    0.946920    0.507208  0.361730"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
